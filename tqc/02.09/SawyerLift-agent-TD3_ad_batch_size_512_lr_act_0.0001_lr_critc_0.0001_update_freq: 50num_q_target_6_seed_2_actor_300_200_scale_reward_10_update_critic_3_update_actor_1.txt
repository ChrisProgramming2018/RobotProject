Star_training target_update_freq: 50  num_q_target: 6  use device cuda 
Namespace(actor_clip_gradient=1.0, batch_size=512, buffer_size=300000.0, debug=False, device='cuda', discount=0.99, env_name='SawyerLift', eval_freq=60000.0, expl_noise=0.1, history_length=3, image_pad=4, last_states_actor=10000.0, locexp='02.09', lr_actor=0.0001, lr_critic=0.0001, max_episode_steps=200, max_timesteps=7000000.0, noise_clip=0.5, num_q_target=6, policy='TD3_ad', policy_freq=1, policy_noise=0.2, repeat_opt=3, reward_scalling=10, save_model=True, seed=2, size=84, start_timesteps=25000.0, target_update_freq=50, tau=0.005, tensorboard_freq=1000)
Star_training target_update_freq: 50  num_q_target: 6  use device cuda 
Namespace(actor_clip_gradient=1.0, batch_size=512, buffer_size=300000.0, debug=False, device='cuda', discount=0.99, env_name='SawyerLift', eval_freq=60000.0, expl_noise=0.1, history_length=3, image_pad=4, last_states_actor=10000.0, locexp='02.09', lr_actor=0.0001, lr_critic=0.0001, max_episode_steps=200, max_timesteps=7000000.0, noise_clip=0.5, num_q_target=6, policy='TD3_ad', policy_freq=1, policy_noise=0.2, repeat_opt=3, reward_scalling=10, save_model=True, seed=2, size=84, start_timesteps=25000.0, target_update_freq=50, tau=0.005, tensorboard_freq=1000)
Total Timesteps: 200 Episode Num: 2 Episode steps 200 Reward: 4.01  Average Re: 2.01 Time: (0.0, 0.0, 8.8)
Total Timesteps: 400 Episode Num: 3 Episode steps 200 Reward: 8.51  Average Re: 4.17 Time: (0.0, 0.0, 17.24)
